学习笔记
----------
这节课中主要学习了三种反爬虫的手段：随机useragent模拟浏览器头部、随机代理ip、cookie验证。其中使用现有cookie再去访问的网页的方式已经通过百度基本有了实践，但在scrapy如何去使用前面的cookie继续访问后面的网页还不是很清楚，希望老师后面能举例补充说明一下。
同时对于scrapy中的中间件的类中的函数参数值怎么传递的也不理解，因为不知道参数值从哪里来的，也就不明白为啥可以参数有哪些方法和值，不知道从哪里追溯从哪里看。希望老师也能够补充说明一下。
本节课中对于分布式爬虫还没应用过。